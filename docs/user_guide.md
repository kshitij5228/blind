# User Guide

## Interactive AI Vision Assistant - Operation Manual

Welcome to the Interactive AI Vision Assistant! This device helps blind and visually impaired users understand their surroundings through AI-powered vision and voice interaction.

---

## Quick Start

### What You'll Need
- Fully assembled device (hardware + firmware)
- Backend server running and accessible
- Wi-Fi network (2.4 GHz)
- Power supply

### First Time Setup
1. Power on the device
2. Wait for status LED to blink (indicating Wi-Fi connection)
3. The device is ready when you hear a short beep (if speaker connected)

---

## How to Use

### Understanding the Button

The device has **one button** with two interaction modes:

#### Short Press (Snapshot Mode)
- **Action:** Press and release quickly (less than 0.5 seconds)
- **Purpose:** Get a description of what's in front of you
- **Process:** Device captures image → sends to AI → describes the scene
- **Use Cases:**
  - "What's in front of me?"
  - "Identify obstacles"
  - "Read signs or labels"

#### Long Press (Conversation Mode)
- **Action:** Press and hold while speaking, release when done
- **Purpose:** Ask specific questions about what you see
- **Process:** Device records your question → captures image → AI answers your question
- **Use Cases:**
  - "What color is this shirt?"
  - "Is there a chair nearby?"
  - "Read the text on this bottle"

---

## Supported Languages

The device automatically detects and responds in your language:
- **English** (en)
- **Hindi** (hi) - हिंदी
- **Marathi** (mr) - मराठी

### How Language Detection Works
1. Speak in your preferred language when using conversation mode
2. The system detects your language automatically
3. AI responds in the same language
4. The language preference is remembered for your session

### Switching Languages
Simply speak in a different language - the system will detect and switch automatically.

---

## Usage Examples

### Example 1: Navigating a Room (Snapshot Mode)
1. **Short press** the button
2. Point the camera toward the area you want to explore
3. Wait 3-5 seconds
4. **Listen** to the description:
   > "There is a wooden table directly in front of you, about 4 feet away. A chair is positioned at your 2 o'clock, approximately 3 feet away. The doorway is to your left."

### Example 2: Identifying Objects (Conversation Mode)
1. **Press and hold** the button
2. Point the camera at the object
3. **Ask:** "What is this?"
4. **Release** the button
5. Wait 5-8 seconds
6. **Listen** to the answer:
   > "This is a water bottle. It's made of plastic and appears to be about half full."

### Example 3: Reading Text (Conversation Mode)
1. **Press and hold** the button
2. Point the camera at the text
3. **Ask:** "Read what this says"
4. **Release** the button
5. **Listen** to the response:
   > "The label reads: 'Orange Juice, 100% natural, best before March 2026.'"

### Example 4: Hindi Usage (हिंदी में)
1. **लंबे समय तक दबाएं** बटन को
2. **पूछें:** "यह क्या है?"
3. **छोड़ें** बटन को
4. **सुनें:**
   > "यह एक पानी की बोतल है। यह प्लास्टिक की बनी है।"

### Example 5: Marathi Usage (मराठीत)
1. **बटण दाबा आणि धरा**
2. **विचारा:** "हे काय आहे?"
3. **बटण सोडा**
4. **ऐका:**
   > "ही एक पाण्याची बाटली आहे। ती प्लास्टिकची बनलेली आहे।"

---

## Best Practices

### For Best Results

1. **Lighting Conditions**
   - Use in well-lit areas when possible
   - Natural daylight works best
   - Indoor lighting is usually sufficient
   - Avoid pointing directly at bright light sources

2. **Camera Positioning**
   - Hold device steady
   - Point camera at the area/object of interest
   - For obstacles: point forward at waist height
   - For reading: point directly at text, 6-12 inches away
   - For object identification: center the object in view

3. **Speaking Clearly (Conversation Mode)**
   - Speak at normal pace
   - Use clear pronunciation
   - Avoid background noise when possible
   - Keep questions concise

4. **Question Tips**
   - Be specific: "What color is this?" vs. "Tell me about this"
   - Ask one question at a time
   - Use natural language
   - Follow-up questions work - the AI remembers context

---

## Understanding Responses

### Spatial Descriptions

The AI uses **clock-face directions** for spatial awareness:
- **12 o'clock:** Straight ahead
- **3 o'clock:** Directly to your right
- **6 o'clock:** Behind you
- **9 o'clock:** Directly to your left
- **2 o'clock:** Ahead and slightly right
- etc.

The AI also provides **distances**:
- "About 2 feet away"
- "Approximately 1 meter in front"
- "Close to you, within arm's reach"

### Example Spatial Description:
> "A coffee mug is at your 2 o'clock position, about 8 inches away. A laptop is directly ahead at 12 o'clock, roughly 2 feet in front of you."

---

## Troubleshooting

### Device Not Responding

**No LED blinking:**
- Check power supply connection
- Verify power switch is ON
- Check battery (if battery-powered)

**LED blinking but no response:**
- Device may not be connected to Wi-Fi
- Check Wi-Fi network availability
- Restart the device

### No Audio Response

**Silent after button press:**
- Check speaker connection (if external speaker)
- Verify backend server is running
- Check Wi-Fi connection
- Wait longer (first response may take up to 10 seconds)

**Error messages:**
- "Rate limit exceeded" - Wait 1 minute before trying again
- "Connection error" - Check Wi-Fi or backend server
- "Sorry, I couldn't analyze the image" - Try again with better lighting

### Poor Description Quality

**Generic or incorrect descriptions:**
- Improve lighting
- Hold device steadier
- Point camera more directly at subject
- Move closer to object (if safe)

**Audio not in expected language:**
- The device detected a different language
- Speak more clearly
- Try asking your question again

---

## Safety Guidelines

### Important Safety Notes

⚠️ **This device is an assistance tool, NOT a replacement for:**
- Guide dogs
- White canes
- Human assistance
- Professional orientation and mobility training

### Safe Usage

1. **Always use traditional mobility aids** (cane, guide dog) when navigating
2. **The device cannot detect:**
   - Moving objects (cars, people in motion)
   - Very small obstacles on the ground
   - Obstacles outside the camera's field of view
3. **Never rely solely on this device** for critical safety decisions
4. **Use in combination with** other senses and mobility techniques

### Privacy Considerations

- Images are temporarily stored and deleted after processing
- Audio is processed and not permanently stored
- Sessions expire after 30 minutes of inactivity
- No personal data is retained long-term
- Use caution when capturing images of people or private information

---

## Maintenance

### Daily Maintenance
- Wipe camera lens with soft cloth if dirty
- Check battery level (if battery-powered)
- Ensure no physical damage to device

### Weekly Maintenance
- Clean microphone port gently
- Check button responsiveness
- Verify speaker is working properly

### Storage
- Store in dry location
- Avoid extreme temperatures
- Remove batteries if storing for extended period

---

## FAQ

**Q: How long does it take to get a response?**
A: Snapshot mode: 3-5 seconds. Conversation mode: 5-8 seconds.

**Q: Can I use this offline?**
A: No, an internet connection is required for AI processing.

**Q: What if I speak in the middle of a sentence and release the button?**
A: The device will process whatever was recorded. Try to complete your question before releasing.

**Q: Can it read handwriting?**
A: It can attempt to read clear handwriting, but printed text works much better.

**Q: Does it work in the dark?**
A: The camera requires some light to function. Very dark conditions will result in poor descriptions.

**Q: Can I ask follow-up questions?**
A: Yes! The system remembers your last 10 interactions in a session.

**Q: How many languages does it support?**
A: Currently English, Hindi, and Marathi. More languages may be added in future updates.

**Q: Is my data private?**
A: Yes. Images and audio are processed transiently and not stored permanently.

**Q: What's the maximum recording time for questions?**
A: The recording buffer can hold up to 30 seconds of audio, but concise questions work best.

**Q: Can multiple people use the same device?**
A: Yes, each session is independent. The device creates a new session automatically.

---

## Language-Specific Tips

### English Users
- Speak clearly and at a normal pace
- Use standard terminology
- The AI understands both US and UK English

### Hindi Users (हिंदी उपयोगकर्ता)
- स्पष्ट रूप से बोलें
- सरल प्रश्न पूछें
- मिश्रित हिंदी-अंग्रेजी (Hinglish) भी समझा जाता है

### Marathi Users (मराठी वापरकर्ते)
- स्पष्टपणे बोला
- साधे प्रश्न विचारा
- मराठी-इंग्रजी मिश्रित भाषा देखील समजते

---

## Getting Help

### Technical Support
- Check the troubleshooting section above
- Consult the hardware and backend setup guides
- Review system logs for error messages

### Community
- Share experiences with other users
- Report bugs or suggest features
- Contribute to documentation improvements

---

## Future Enhancements

Planned features for future versions:
- More language support
- Object tracking and navigation guidance
- Voice-only mode (without button)
- Customizable response verbosity
- Offline mode for basic descriptions
- Integration with smart home devices

---

## Accessibility Notes

This device is designed **by and for** the blind and visually impaired community:
- Single-button interface for simplicity
- Audio-first design
- No visual feedback required for operation
- Spatial descriptions using familiar reference systems
- Support for multiple languages

---

## Conclusion

The Interactive AI Vision Assistant empowers you to:
- Understand your surroundings independently
- Identify objects and read text
- Navigate spaces more confidently
- Ask questions about your environment in your native language

**Remember:** This is an assistance tool to complement, not replace, traditional mobility aids and techniques.

Stay safe and enjoy your enhanced independence!

---

## Contact & Feedback

For questions, suggestions, or support:
- Email: [your-email@domain.com]
- GitHub: [your-github-repo]
- Documentation: See other guides in the `/docs` folder

**Thank you for using the Interactive AI Vision Assistant!**
